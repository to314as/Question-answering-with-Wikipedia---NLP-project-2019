# Question answering with Wikipedia - NLP project 2019
We propose and explore a QA system based on data form Wikipedia and the Stanford Question Answering Dataset. We show different approaches to document retrival as well as reading. Including tf-idf and term frequency for retrival. Language models such as word2vec(glove), infersent(sentence2vec by fb research), Bert,... Furthermore to we apply different supervised as well as unsupervised approaches for the question answering aspect.

# 1)Summary:
For this project we outline a NLP framework that is able to find answers to simple questions within a set of articles. We created an algorithm that retrieves relevant articles and paragraphs within the article, based on multiple features including the similarity of keywords. Furthermore we propose a system to retrieve more natural exact answers, which are only spans of a sentence, exploiting techniques of part of speech tagging and leveraging recurrent neural networks. With this we hope to support students and enthusiasts by providing them a way to deepen their knowledge and find answers to domain specific questions easier and quicker.

The focus of the project is on comprehensions of the massive English Wikipedia and SQuAD corpus for training and testings. We tackle the problem of a question answering system by limiting our self to a subset of Wikipedia, due to its massive size.
We outline results using bag of word models, word2vec, sentence2vec representations in combination with different classification methods for text retrieval and comprehension. All implementations will are done in python leveraging multiple standard libraries such as numpy, pandas, nltk and gensim. The machine/deep learning components are be based on the pytorch framework which allows efficient use of resources as well as quick prototyping. Results are presented in form of a Jupyter notebook.
# 2)Results:

# 3)Further Research:

_Do it yourself:_
1) Setup:
2) Execution:
